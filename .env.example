# .env.example - Environment variables for the Inference Providers Metrics Tracker

# --- Secrets ---
# DO NOT commit your actual secrets to Git. Use a real .env file for them.
# Hugging Face API token for making inference calls (read permissions usually suffice)
HF_TOKEN="hf_YOUR_INFERENCE_API_TOKEN"

# Hugging Face Hub token for pushing data to the dataset repository (requires write permissions)
HF_HUB_TOKEN="hf_YOUR_HUB_WRITE_TOKEN"


# --- Hugging Face Dataset Configuration ---
# The ID of the Hugging Face Dataset repository to push results to (e.g., "YourUsername/YourDatasetName")
HF_DATASET_REPO_ID="YourUsername/inference-metrics"

# The target filename within the HF Dataset repository
HF_DATASET_TARGET_FILENAME="metrics.csv"


# --- Scheduler Configuration ---
# How often to run the monitoring cycle, in seconds (e.g., 1800 = 30 minutes)
SCHEDULE_INTERVAL_SECONDS=1800

# How many cycles to wait before pushing the local CSV buffer to the Hub (e.g., 1 cycle * 30 minutes/cycle = 30 minutes)
# Adjust PUSH_INTERVAL_CYCLES if you want to push less frequently than every cycle.
PUSH_INTERVAL_CYCLES=6


# --- Model & Inference Configuration ---
# How many top trending models to fetch and test in each cycle
MODELS_TO_FETCH=5

# Default maximum number of tokens to request in the inference call payload
MAX_TOKENS_DEFAULT=512

# Path to the JSON file containing the mapping from provider names to their API endpoint URLs
PROVIDER_ENDPOINT_MAPPING_PATH="./provider_mapping.json"


# --- Local Storage ---
# Path to the local file used to buffer CSV results before pushing to the Hub
LOCAL_CSV_PATH="./metrics_buffer.csv"


# --- Logging ---
# Log level for the application (e.g., 'trace', 'debug', 'info', 'warn', 'error', 'fatal')
LOG_LEVEL="info"
